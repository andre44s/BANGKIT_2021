{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capstone.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IntyLS72HHIj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from imgaug import augmenters as iaa\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36Nkq2jA9Jg9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWVR5wJG-bBf"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "%cd /content/gdrive/My Drive/Kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifktlAbK-m6V"
      },
      "source": [
        "!kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b-_HaXq_AsC"
      },
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "shutil.rmtree('/content/gdrive/MyDrive/Kaggle/face_data')\n",
        "zip_loc = '/content/gdrive/MyDrive/Kaggle/face-expression-recognition-dataset.zip'\n",
        "data_loc = '/content/gdrive/MyDrive/Kaggle/face_data'\n",
        "data_extract = zipfile.ZipFile(zip_loc, 'r')\n",
        "data_extract.extractall(data_loc)\n",
        "data_extract.close()\n",
        "\n",
        "shutil.rmtree('/content/gdrive/MyDrive/Kaggle/face_data/images/images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLdnhYgsDKOI"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_dir = '/content/gdrive/MyDrive/Kaggle/face_data/images/train'\n",
        "valid_dir = '/content/gdrive/MyDrive/Kaggle/face_data/images/validation'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    horizontal_flip=True,\n",
        "    zca_whitening=True,\n",
        "    brightness_range=(0.5, 1.5),\n",
        "    zoom_range=(0.5, 1.5),\n",
        "    shear_range=0.3,\n",
        "    fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(48, 48),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=256,\n",
        "    class_mode='categorical',\n",
        ")\n",
        "\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=(48, 48),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=256,\n",
        "    class_mode='categorical',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da3N6JEQA-af"
      },
      "source": [
        "x_batch, y_batch = next(train_generator)\n",
        "x= train_generator.next()\n",
        "\n",
        "plt.figure(figsize=(25,25)) # specifying the overall grid size\n",
        "\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)    # the number of images in the grid is 5*5 (25)\n",
        "    image = x_batch[i]\n",
        "    plt.imshow((tf.squeeze(image)))\n",
        "    #plt.imshow(image)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQp9j5pmE6ZW"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy') > 0.9 and logs.get('val_accuracy') > 0.9):\n",
        "            print(\"\\nAccuracy is Optimal\")\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO4QXRuIE__f"
      },
      "source": [
        "callbacks = myCallback()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Dense(7, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='Nadam',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiEJRpqsFXvn"
      },
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=50,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=5,\n",
        "    verbose=1,\n",
        "    callbacks=[callbacks]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZTy1edbR9jo"
      },
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "import numpy\n",
        "\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"weights.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}